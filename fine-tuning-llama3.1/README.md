# Fine-Tuning Llama 3.1 8B LoRA con Unsloth

Este repositorio contiene el c贸digo y las instrucciones para realizar fine-tuning del modelo Llama 3.1 8B utilizando LoRA (Low-Rank Adaptation) y la biblioteca Unsloth. Este tutorial est谩 basado en un video de YouTube que muestra paso a paso c贸mo implementar estas t茅cnicas avanzadas de ajuste de modelos de lenguaje.

## Descripci贸n

Este proyecto demuestra c贸mo utilizar t茅cnicas de fine-tuning eficientes en t茅rminos de recursos para mejorar el rendimiento de modelos de lenguaje de gran escala. Utilizamos LoRA para adaptar el modelo Llama 3.1 8B de manera eficiente, y aprovechamos las optimizaciones proporcionadas por Unsloth para acelerar el proceso de entrenamiento.

## Tutorial en Video

Puedes ver el tutorial completo y la explicaci贸n detallada del proceso de fine-tuning aqu铆 金:

[![Watch this video on YouTube](https://img.youtube.com/vi/--l1HXN6gXc/0.jpg)](https://www.youtube.com/watch?v=--l1HXN6gXc)

## Requisitos

- Python 3.8 o superior
- CUDA compatible GPU (recomendado)
- Dependencias listadas en el notebook

## Instalaci贸n

1. **Clonar el repositorio:**
   ```bash
   gh repo clone codingmindset/CodingMindset-YouTube
   cd fine-tuning-llama3.1
   ```

2. **Instalar dependencias:**
Instala las dependencias siguiendo las instrucciones del notebook


## Uso

El notebook principal `CodingMindset_Fine_Tuning_con_Unsloth.ipynb` contiene todo el c贸digo necesario para realizar el fine-tuning. Sigue estos pasos:

1. Abre el notebook en Google Colab o en tu entorno local con Jupyter.
2. Ejecuta las celdas en orden, siguiendo las instrucciones y comentarios proporcionados.
3. Ajusta los hiperpar谩metros seg煤n tus necesidades espec铆ficas.

## Caracter铆sticas Principales

- Fine-tuning de Llama 3.1 8B usando QLoRA
- Utilizaci贸n de Unsloth para optimizaci贸n de rendimiento
- Soporte para diferentes configuraciones de cuantizaci贸n
- Guardado y carga de modelos en formatos eficientes (LoRA, merged_16bit, merged_4bit)
- Conversi贸n a formato GGUF para compatibilidad con diversos motores de inferencia

## Contribuciones

Las contribuciones son bienvenidas. Por favor, abre un issue o un pull request para sugerencias de mejoras o correcciones.

## Licencia

Este proyecto est谩 bajo la licencia [insertar tipo de licencia].

---

## Redes Sociales

S铆gueme en mis redes sociales para m谩s contenido sobre IA y programaci贸n:

- Twitter: [@codingmindsetio](https://twitter.com/codingmindsetio)
- YouTube: [CodingMindset](https://www.youtube.com/@CodingMindsetIO?sub_confirmation=1)
- Instagram: [@codingmindset](https://www.instagram.com/codingmindset)

隆No olvides dejar tu like y comentario en el video si te ha sido 煤til! Tu apoyo me ayuda a seguir creando contenido educativo de calidad.